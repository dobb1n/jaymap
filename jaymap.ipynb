{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make API call of Guardian to return all Jay Rayner articles. First query the API for the list of articles - this returns a page of results. We fetch the first batch of links to follow here, then we need to work through the rest of the list of pages, getting all those links.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re \n",
    "import os\n",
    "\n",
    "page_size = 15\n",
    "page = 1\n",
    "\n",
    "#we need to fail if the key isnt set\n",
    "try:\n",
    "    api_key = os.environ['GUARDIAN_API_KEY']\n",
    "except:\n",
    "    raise SystemExit(\"specify the API key as an env var before continuing\")\n",
    "\n",
    "\n",
    "#base url which looks for the jay tags \n",
    "url = f\"https://content.guardianapis.com/search?api-key={api_key}&tag=food/series/jay-rayner-on-restaurants&page-size={page_size}\"\n",
    "payload = {}\n",
    "headers = {\n",
    "  'Cookie': 'AWSELB=75B9BD811C5C032EDEF76366759629DCCB8726D7A371904BEC1C3B7DFC40019571E370E2C4E4519DDF3CD336789F71716B110728D88A7C69AE901D39C1821FF2C5E227F5F9; AWSELBCORS=75B9BD811C5C032EDEF76366759629DCCB8726D7A371904BEC1C3B7DFC40019571E370E2C4E4519DDF3CD336789F71716B110728D88A7C69AE901D39C1821FF2C5E227F5F9; BCSI-CS-682e9ee7ab0fdcff=1'\n",
    "}\n",
    "\n",
    "#function to go through the results\n",
    "def review_grabber(apiresults, count):\n",
    "    #we need to open two files to save the results in, then we need to send them to the gsheet as separate layers\n",
    "    with open('jaymap_pcode.tsv', 'a') as pcode_tsv_file, open(\"jaymap_nocode.tsv\", 'a') as nocode_tsv_file:\n",
    "        #if status is ok, work through the list of results and find the postcodes in the linked articles\n",
    "        if apiresults['response']['status'] == 'ok':\n",
    "            for result in apiresults['response']['results']:\n",
    "                #print(f\"visiting {result['webUrl']}, {count}, {len(apiresults)}\")\n",
    "                article = requests.request(\"GET\", result['webUrl'], headers=headers, data = payload)\n",
    "                postcode = re.findall(r'\\b[A-Z]{1,2}[0-9][A-Z0-9]? [0-9][ABD-HJLNP-UW-Z]{2}\\b', article.text)\n",
    "                #if there is a postcode print it, to avoid out of bounds error caught in if loop\n",
    "                if len(postcode) > 0:\n",
    "                    #output as TSV as there are commas in some of the titles\n",
    "                    pcode_tsv_file.write(f\"\\n{result['webTitle']}\\t{result['webUrl']}\\t{postcode[0]}\\t{result['webPublicationDate']}\")\n",
    "                    print(count, result['webTitle'], result['webUrl'], postcode[0], result['webPublicationDate'])\n",
    "                else:\n",
    "                    nocode_tsv_file.write(f\"\\n{result['webTitle']}\\t{result['webUrl']}\\t{result['webPublicationDate']}\")\n",
    "                    print(count, result['webTitle'], result['webUrl'], result['webPublicationDate'])\n",
    "                count += 1 \n",
    "            return count\n",
    "\n",
    "#fetch the first page listing articles by jay\n",
    "response = requests.request(\"GET\", url, headers=headers, data = payload)\n",
    "responsejson = response.json()\n",
    "\n",
    "pages = responsejson['response']['pages']\n",
    "#total articles to check off later\n",
    "total_articles = responsejson['response']['total']\n",
    "print(f\"there are {pages} pages of articles to get, {page_size} articles on each page, {total_articles} articles in total\")\n",
    "#send the whole response into the function to visit the page and get the postcode\n",
    "count = 0 \n",
    "count = review_grabber(responsejson, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#work through the rest of the pages getting the links\n",
    "page = 2\n",
    "while page <= pages:\n",
    "    print(page)\n",
    "    url = f\"https://content.guardianapis.com/search?api-key={api_key}&tag=food/series/jay-rayner-on-restaurants&page-size={page_size}&page={page}\"\n",
    "    response2 = requests.request(\"GET\", url, headers=headers, data = payload)\n",
    "    response2json = response2.json()\n",
    "    count = review_grabber(response2json, count)\n",
    "    page += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_size = 5\n",
    "page = 2\n",
    "api_key = os.environ.get('GUARDIAN_API_KEY')\n",
    "\n",
    "#base url which looks for the jay tags \n",
    "url = f\"https://content.guardianapis.com/search?api-key={api_key}&tag=food/series/jay-rayner-on-restaurants&page-size={page_size}&page={page}\"\n",
    "payload = {}\n",
    "headers = {\n",
    "  'Cookie': 'AWSELB=75B9BD811C5C032EDEF76366759629DCCB8726D7A371904BEC1C3B7DFC40019571E370E2C4E4519DDF3CD336789F71716B110728D88A7C69AE901D39C1821FF2C5E227F5F9; AWSELBCORS=75B9BD811C5C032EDEF76366759629DCCB8726D7A371904BEC1C3B7DFC40019571E370E2C4E4519DDF3CD336789F71716B110728D88A7C69AE901D39C1821FF2C5E227F5F9; BCSI-CS-682e9ee7ab0fdcff=1'\n",
    "}\n",
    "count = 1\n",
    "#function to go through the results\n",
    "def review_grabber(apiresults, count):\n",
    "    with open('jaymap_new.csv', 'a') as csvfile:\n",
    "        #if status is ok, work through the list of results and find the postcodes in the linked articles\n",
    "        if apiresults['response']['status'] == 'ok':\n",
    "            for result in apiresults['response']['results']:\n",
    "                article = requests.request(\"GET\", result['webUrl'], headers=headers, data = payload)\n",
    "                postcode = re.findall(r'\\b[A-Z]{1,2}[0-9][A-Z0-9]? [0-9][ABD-HJLNP-UW-Z]{2}\\b', article.text)\n",
    "                if len(postcode) > 0:\n",
    "                    csvfile.write(f\"\\n{count},{result['webTitle']},{result['webUrl']},{postcode[0]}\")\n",
    "                    print(count, result['webTitle'], result['webUrl'], postcode[0])\n",
    "                count += 1\n",
    "            return count\n",
    "\n",
    "#fetch the first page listing articles by jay\n",
    "response = requests.request(\"GET\", url, headers=headers, data = payload)\n",
    "responsejson = response.json()\n",
    "responsejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#how many pages are there in the response, as we will need to get them all\n",
    "pages = responsejson['response']['pages']\n",
    "#total articles to check off later\n",
    "total_articles = responsejson['response']['total']\n",
    "print(f\"there are {pages} pages of articles to get, {page_size} articles on each page, {total_articles} articles in total\")\n",
    "#send the whole response into the function to visit the page and get the postcode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
